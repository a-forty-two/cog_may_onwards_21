{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cog_tf_005.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhFfLjINgSE5ZvrCQXXBrx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPuTJWGuv-Jm"
      },
      "source": [
        "# Flatten -> 2 D input was transformed into 1 D\n",
        "# Dense -> fully connected layers, responsible for generating weights and biases for ML \n",
        "# Embedding \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fotsf_gKxs9s"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nr5fJTA2aP_",
        "outputId": "08644baf-70cf-4c42-839f-06ae87134791"
      },
      "source": [
        "(trainx,trainy), (testx, testy) = tf.keras.datasets.imdb.load_data(num_words=10000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuajQpKB2sZa",
        "outputId": "b8468f16-5423-4ce9-e07f-53f0de37fc76"
      },
      "source": [
        "trainy[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0IdDtup2vbE",
        "outputId": "b79ac998-0e61-42f7-b1a3-4cbe37c1258e"
      },
      "source": [
        "print(testx[9])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 9, 121, 4, 1354, 3135, 3882, 8, 28, 2230, 151, 13, 80, 2, 15, 4, 1008, 496, 1354, 1437, 71, 321, 5, 100, 28, 77, 714, 5372, 34, 6, 3275, 167, 17, 12, 679, 46, 14, 16, 24, 8, 30, 4, 420, 10, 10, 684, 2991, 1094, 7129, 71, 685, 19, 89, 465, 14, 333, 1354, 22, 39, 1756, 3555, 679, 46, 972, 39, 4, 8801, 7, 1017, 233, 334, 39, 3555, 5, 4, 4528, 2, 7, 68, 3691, 2154, 8, 471, 4, 3135, 83, 35, 3490, 8, 4, 4997, 248, 201, 13, 1854, 8, 391, 89, 1354, 1747, 70, 30, 1192, 33, 32, 1332, 10, 10, 283, 12, 9, 24, 179, 4, 3215, 7, 4, 86, 22, 151, 12, 2, 32, 4, 1403, 2, 7, 405, 258, 11, 1354, 6, 6118, 229, 15, 2, 4, 2, 200, 24, 43, 107, 21, 289, 105, 5386, 2, 5719, 8, 4, 4796, 8173, 7, 2065, 5, 718, 4462, 17, 4, 6199, 11, 4, 86, 22, 246, 18, 32, 14, 12, 1287, 6, 2, 465, 22, 283, 8, 4, 96, 4, 1354, 16, 210, 981, 8, 30, 5, 545, 2349, 10, 10, 488, 2065, 1747, 17, 4, 1354, 5, 27, 6765, 3530, 1478, 2451, 19, 2, 2431, 2, 1368, 3590, 773, 11, 9658, 7, 4, 8712, 1124, 1295, 284, 27, 1943, 11, 823, 2, 2, 4, 8976, 1738, 2, 11, 530, 2430, 2781, 7, 5428, 2, 745, 3448, 5, 2, 5134, 4, 2, 2861, 6984, 937, 2451, 6978, 199, 17, 309, 5, 17, 4, 1354, 4, 689, 6495, 471, 11, 321, 354, 262, 3590, 5, 2, 137, 295, 2065, 5, 6984, 3739, 4, 3778, 499, 7, 1405, 8681, 10, 10, 50, 26, 49, 1774, 5867, 11, 14, 22, 44, 4, 64, 5340, 13, 70, 66, 213, 46, 9, 6, 813, 8, 4, 229, 11, 49, 1370, 63, 13, 104, 9, 688, 669, 8, 4, 96, 14, 22, 9, 6, 689, 2, 548, 50, 331, 218, 195, 58, 8, 2887, 3739, 803, 170, 23, 10, 10, 2185, 14, 9, 6, 1543, 52, 22, 13, 545, 386, 149, 14, 11, 2, 19, 4, 86, 5, 95, 2, 18, 89, 52, 4, 201, 100, 28, 77, 69, 12, 3501, 467, 3555, 5, 2065]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBIZtvvS2zIb"
      },
      "source": [
        "data = tf.keras.datasets.imdb"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcC9Up0Y299Y",
        "outputId": "72438edc-4307-4cdc-bb91-bfe9531f70d6"
      },
      "source": [
        "dir(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_sys',\n",
              " 'get_word_index',\n",
              " 'load_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5KmTyC32-02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8671f9c-fcb0-4318-bd34-38486fe9607a"
      },
      "source": [
        "reverse_dictionary = data.get_word_index()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmLteOAT3MSi",
        "outputId": "a89f49fe-883a-4863-a7fe-38052d3e8338"
      },
      "source": [
        "reverse_dictionary['bye']\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5455"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0rq8SCf52Z1"
      },
      "source": [
        "\n",
        "word_index = {word:(encoding+3) for word,encoding in reverse_dictionary.items()}\n",
        "word_index['<PAD>'] = 0\n",
        "word_index['<START>'] = 1\n",
        "word_index['<UNK>'] = 2  # unknown words\n",
        "word_index['<UNUSED>'] = 3\n",
        "olddictionary = { encoding:word  for word,encoding in word_index.items()   }"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjoa3Vns3mZa"
      },
      "source": [
        "dictionary = {}\n",
        "for i in range(10000):\n",
        "  dictionary[i] = olddictionary[i]\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVLuhkrS3oGu",
        "outputId": "07e829af-8ae0-4c58-a677-8ec3bccb3589"
      },
      "source": [
        "len(dictionary)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFGAx-u-3zEm"
      },
      "source": [
        "# NLP keywords-> \n",
        "# 0 <PAD> \n",
        "# 1 <START>\n",
        "# 2 <UNK>\n",
        "# 3 <UNUSED>\n",
        "\n",
        "# To NORMALIZE-> we make sure all INPUTS are of SAME length\n",
        "# small sentences will be padded with 0 towards the end\n",
        "# large sentences will be CHOPPED into shorter length! "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0lLWgWW6L0R"
      },
      "source": [
        "def decoder(sampleinput):\n",
        "  return \" \".join([dictionary[word] for word in sampleinput])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "War58BVX6YEl",
        "outputId": "a7b24f03-69f8-4a34-fdc2-9c204ce68979"
      },
      "source": [
        "decoder(testx[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-6V9qvx6eQV",
        "outputId": "622a6605-5538-48af-d3e4-751ca224741e"
      },
      "source": [
        "testy[0] # 0-> negative sentiment"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxsZ7eGV7RWY",
        "outputId": "97ebc6d5-6992-4278-cf9a-5359a0ae09bf"
      },
      "source": [
        "testy[41] # 1-> positive sentiment!\n",
        "\n",
        "# sentiment = f(sentence)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "vpRh_lwe7U_i",
        "outputId": "6df1a317-41b9-4f8c-ba2e-d84d8721ee3b"
      },
      "source": [
        "decoder(testx[41])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<START> little <UNK> needs to fly is another in the remarkable body of <UNK> <UNK> <UNK> work that is without <UNK> having recently <UNK> it on dvd nearly a decade after its initial us release in 1997 it has lost none of its power and one can see its influence on documentaries as diverse as <UNK> own recent <UNK> man and errol <UNK> academy award winning the fog of war like the former it details in its far too brief <UNK> minutes the life of an interesting american like the latter it gives a <UNK> at a side of war that few see yes we see the violence and the <UNK> but as the fog of war brought us into the mind of one of last <UNK> foremost this film allows us a <UNK> at the life of a <UNK> who is captured by the enemy tortured and ultimately <UNK> except in no way shape nor form is the film as simplistic nor upbeat as my brief description of it nor is little <UNK> needs to <UNK> titular subject <UNK> and immigrant german who survived the of the nazis we find out as example that in his hometown in the black forest his grandfather was the only man not to vote for hitler and suffered brutally for that stand post world war two germany and his own <UNK> at the hands of the <UNK> when his air force jet was shot down over on <UNK> 1st while the title of the film and the idea of passion for becoming a pilot <UNK> by the impression allied fighter planes made on him when they <UNK> his town as a child make one believe that is the central subject of the film this is not true the subject is survival or more precisely his human will all human will the details of romantic life are too hollywood and <UNK> an aspect to interest <UNK> nor is the fact that he won a purple heart <UNK> of honor the d f c and the navy cross that thing which pushed to survive so much and remain such a relatively upbeat man although there are glimpses of darker sides is what is at the center of this film and all of <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> of his past is fully <UNK> <UNK> country and the use of a <UNK> e during many jungle scenes among other excellent touches in the score show <UNK> is perhaps along with only martin scorsese the best <UNK> of image and music in film long may he <UNK>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg2zfEN-7bNP",
        "outputId": "8dd99452-f7b2-42a0-8d88-55de3beb5398"
      },
      "source": [
        "xtrain_padded = keras.preprocessing.sequence.pad_sequences(trainx, value=0, padding='post',\n",
        "                                                           truncating='post', maxlen=256)\n",
        "xtest_padded = keras.preprocessing.sequence.pad_sequences(testx, value=0, padding='post', \n",
        "                                                          truncating='post', maxlen=256)\n",
        "print(decoder(trainx[142]))\n",
        "print(decoder(xtrain_padded[142])) # LONG SENTENCE CHOPPED\n",
        "print(decoder(trainx[162])) # SHORT SENTENCE PADDED\n",
        "print(decoder(xtrain_padded[162]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> while i would say i enjoy the show i expected something completely different from when i first saw <UNK> i like about <UNK> i expected to find something along the lines of <UNK> <UNK> i am not sure if it is going on anymore but i have to say i do like the show and while i don't <UNK> it as a breakthrough show it is very charming and i do like the chemistry between the characters as well including the supporting cast br br i would definitely say that it is great to see wesley jonathan back on the screen because i really loved him in city guy i had also seen the woman who plays <UNK> friend in popular and while i think that was an okay show i do not really like her character in this show because she's just not my cup of tea but she rounds it out pretty well\n",
            "<START> while i would say i enjoy the show i expected something completely different from when i first saw <UNK> i like about <UNK> i expected to find something along the lines of <UNK> <UNK> i am not sure if it is going on anymore but i have to say i do like the show and while i don't <UNK> it as a breakthrough show it is very charming and i do like the chemistry between the characters as well including the supporting cast br br i would definitely say that it is great to see wesley jonathan back on the screen because i really loved him in city guy i had also seen the woman who plays <UNK> friend in popular and while i think that was an okay show i do not really like her character in this show because she's just not my cup of tea but she rounds it out pretty well <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "<START> i pulled down a vhs box from my vast collection many unseen and picked out a movie based on the box art i thought would be fun and yes bad prison had that 80s cheesy look all over that box i sat down and watched and lo and behold found that sometimes we do indeed sit down to a movie with <UNK> expectations in mind fortunately i <UNK> mine quickly and soon realized i was sitting down not just to an okay film but a rather good movie in total prison tells the story of an old <UNK> prison being <UNK> to save on <UNK> concerns it looks creepy as all empty and filled with prisoners the prison used as a set is incredibly atmospheric and easily the most important character in the film the story using the prison as its central setting tells in a prologue of a man being killed via the electric chair we see lane smith as a guard <UNK> away a <UNK> before sending the man to his maker we then go to present day first with a government board at a meeting deciding to open the prison and send a beautiful doctor in to make sure that conditions are acceptable as she <UNK> <UNK> against re opening the old prison then we see the new warden lane smith haunted by a nightmare in bed and given the new job of opening a prison he has not been to in years well the rest follows suit prisoners and guards arrive with plenty of stereotypes <UNK> we are given some character depth and several of the prisoners are interesting characters the acting is better than one might expect with lane smith doing as always a <UNK> job viggo <UNK> as a very different prisoner being solid tom everett tiny <UNK> and <UNK> kane really exploring the boundaries of their stereotypical characters <UNK> field is okay as the female lead the best performance is by lincoln <UNK> an underrated character actor as <UNK> a prisoner who had been in that very same prison years ago when the man had been executed with some kind of terrible secret prison is not the next best thing to <UNK> bread or anything like that but it is definitely worth a look and definitely better than most would expect from it i was pleasantly surprised at the way director <UNK> <UNK> created a story so visually atmospheric the film has a tense taut pace and <UNK> knows how to build his scenes there are a few <UNK> shot gore scenes the one with the <UNK> wire was a bit much as was the one with all the <UNK> but these scenes are visually creative and interesting the acting is uniformly decent the script actually much more cohesive than one usually gets from films like these that may in part be credited to irwin <UNK> who wrote the story you may remember he came up with the idea of making halloween scary as a holiday here he makes <UNK> a hell of a lot more scarier than it already is give prison a break get it\n",
            "<START> i pulled down a vhs box from my vast collection many unseen and picked out a movie based on the box art i thought would be fun and yes bad prison had that 80s cheesy look all over that box i sat down and watched and lo and behold found that sometimes we do indeed sit down to a movie with <UNK> expectations in mind fortunately i <UNK> mine quickly and soon realized i was sitting down not just to an okay film but a rather good movie in total prison tells the story of an old <UNK> prison being <UNK> to save on <UNK> concerns it looks creepy as all empty and filled with prisoners the prison used as a set is incredibly atmospheric and easily the most important character in the film the story using the prison as its central setting tells in a prologue of a man being killed via the electric chair we see lane smith as a guard <UNK> away a <UNK> before sending the man to his maker we then go to present day first with a government board at a meeting deciding to open the prison and send a beautiful doctor in to make sure that conditions are acceptable as she <UNK> <UNK> against re opening the old prison then we see the new warden lane smith haunted by a nightmare in bed and given the new job of opening a prison he has not been to in years well the rest follows suit prisoners and guards arrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq-yRHLi8FL5",
        "outputId": "82f98486-1790-48ad-e9c1-d6cd34fc0ab2"
      },
      "source": [
        "len(trainx)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIMjOLV78lZE"
      },
      "source": [
        "# vocab size = 10,000\n",
        "# hyperparams\n",
        "HP_vocab_size = 10000\n",
        "HP_input_dim = 16\n",
        "# weights generated for embedding -> 10000 X 160 => 160000 \n",
        "HP_hidden_dim = [64, 128, 256]\n",
        "HP_output_dim = 2\n",
        "HP_epochs = 50\n",
        "HP_initial_lr = 0.01\n",
        "HP_batch_size = 32\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYf1G_cSEJMh"
      },
      "source": [
        "layer1 = keras.layers.Embedding(HP_vocab_size, HP_input_dim)\n",
        "layer2 = keras.layers.GlobalAveragePooling1D()\n",
        "layer3 = keras.layers.Dense(HP_hidden_dim[0], activation = tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.1))\n",
        "layer3b = keras.layers.Dense(HP_hidden_dim[1], activation = tf.nn.relu)\n",
        "layer4 = keras.layers.Dense(HP_output_dim, activation = tf.nn.softmax)\n",
        "model1 = keras.models.Sequential([layer1,layer2,layer3,layer3b,layer4])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUZtna9YE2FX"
      },
      "source": [
        "layer1 = keras.layers.Embedding(HP_vocab_size, HP_input_dim)\n",
        "layer2 = keras.layers.GlobalAveragePooling1D()\n",
        "layer3 = keras.layers.Dense(HP_hidden_dim[0], activation = tf.nn.relu)\n",
        "layer3b = keras.layers.Dropout(0.25)\n",
        "layer4 = keras.layers.Dense(HP_hidden_dim[1], activation = tf.nn.relu)\n",
        "layer4b = keras.layers.Dense(1, activation = tf.nn.sigmoid)\n",
        "model2 = keras.models.Sequential([layer1,layer2,layer3,layer3b,layer4,layer4b])"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVnVRkJM-MMS"
      },
      "source": [
        "layer1 = keras.layers.Embedding(HP_vocab_size, HP_input_dim)\n",
        "layer2 = keras.layers.GlobalAveragePooling1D()\n",
        "layer3 = keras.layers.Dense(HP_hidden_dim[0], activation = tf.nn.relu)\n",
        "layer3b = keras.layers.Dropout(0.02)\n",
        "layer4 = keras.layers.Dense(HP_hidden_dim[1], activation = tf.nn.relu, bias_regularizer=tf.keras.regularizers.l1(0.01))\n",
        "layer4b = keras.layers.Dense(1, activation = tf.nn.sigmoid)\n",
        "modelx = keras.models.Sequential([layer1,layer2,layer3,layer3b,layer4,layer4b])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUXJNlyYFVu3"
      },
      "source": [
        "model1.compile(loss=tf.losses.sparse_categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "modelx.compile(loss=tf.losses.binary_crossentropy, optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YW8MibvGV-N"
      },
      "source": [
        "xval = xtest_padded[:10000]\n",
        "xtest_new = xtest_padded[10000:]\n",
        "yval = testy[:10000]\n",
        "ytest_new = testy[10000:]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "UzGhRiskJZWu",
        "outputId": "752d9bb1-092f-4379-fc40-bc62b688be2b"
      },
      "source": [
        "decoder(xval[29])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> the back of the dvd for this movie <UNK> is the quentin tarantino of christian films this isn't so much an insult to quentin as it is to christian films this film is poorly written <UNK> acted and edited with a <UNK> intensity the scenes play out in a confusing and unrealistic way and are interspersed with some nice time <UNK> photography flashbacks fades to grey freeze frames to tell the time <UNK> in the story are all done with out any apparent reason other than to give the movie more cinematic credibility the camera is <UNK> some nice <UNK> shots are cut with ridiculous montages that have no significance poor <UNK> and lighting leave the viewer wondering who is talking to who in many scenes oh and the audio is terrible the special effects were decent and thankfully limited but this is all just technical the movie fails to engage on an emotional level the dialogue is so fake sounding and the actors seem to have only read it a moment before the camera was rolling the story the things that happen in sequence have no motivation behind them the characters are struggling to take hold of one <UNK> and the characters have to make a stance on christianity and faith in every single scene take a <UNK> from m night engaging christian films don't have to have the characters saying the name of jesus christ in every scene for the movie to be christian goodness please don't try to show this to your\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHH7UYWSF6QU",
        "outputId": "c9b13af6-97ce-40a9-f0ec-c702b9b5d596"
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "history_m1 = model1.fit(xtrain_padded, trainy, epochs=5, batch_size=HP_batch_size, validation_data = (xval, yval), verbose=0) \n",
        "end_time = time.time()\n",
        "print('Time Taken = ' + str(end_time-start_time))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time Taken = 21.031595468521118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMDtJggl5nHC",
        "outputId": "89703cad-f7de-456f-9639-c652e2dc9645"
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "history_m2 = model2.fit(xtrain_padded, trainy, epochs=5, batch_size=HP_batch_size, validation_data = (xval, yval), verbose=0) \n",
        "end_time = time.time()\n",
        "print('Time Taken = ' + str(end_time-start_time))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time Taken = 41.593947649002075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-UdEjEm-fYt",
        "outputId": "0393e890-e73e-436b-9df4-e32162f7ee8d"
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "history_mx = modelx.fit(xtrain_padded, trainy, epochs=5, batch_size=HP_batch_size, validation_data = (xval, yval), verbose=0) \n",
        "end_time = time.time()\n",
        "print('Time Taken = ' + str(end_time-start_time))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time Taken = 21.138300895690918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrOgYLyt_RLU"
      },
      "source": [
        "# VECTORIZATION representing entire sentence \n",
        "# vector_math_magic() -> single vector -> fictional_boundary-> 2i-3j\n",
        "# any vector > 2i-3j should be learnt as pos, other neg!\n",
        "# AVERAGE out of it!\n",
        "# layer-> GlobalAveragePooling -> take a window of data-> calculate average-> move to next window!\n",
        "# Algorithm?\n",
        "# Calculate mega vectors -> take their average-> learn pattern on these avg via ML!\n",
        "# learn pattern on these avg via ML -> 2 dense layers so that weights and biases can be generated\n",
        "# SOFTMAX or SIGMOID-> distribution b/w pos/neg or a single probability!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL6oVDcBBfFS"
      },
      "source": [
        "predictions = model1.predict(xtest_new)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sq7pjMDKk-R",
        "outputId": "3caeaf8c-ca35-4ab5-df5f-50c6ea17f4dc"
      },
      "source": [
        "perf = model1.evaluate(xtest_new, ytest_new)\n",
        "perf"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3765 - accuracy: 0.8628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37647050619125366, 0.8628000020980835]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsMvMoIa6oRj",
        "outputId": "8d2879dd-62e0-48d1-d9d4-04f7298ee1bf"
      },
      "source": [
        "perf2 = model2.evaluate(xtest_new, ytest_new)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.8495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kao6CvW7-_DY",
        "outputId": "b8f96b46-9d5c-4293-e39c-6288d16354ea"
      },
      "source": [
        "perfx = modelx.evaluate(xtest_new, ytest_new)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4176 - accuracy: 0.8497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOyktgCDKywu",
        "outputId": "ef4fd432-e1bd-4034-b0fb-f399e39fabd0"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                1088      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 161,218\n",
            "Trainable params: 161,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onZYVTwTK4A3"
      },
      "source": [
        "# 3 algorithms that help you narrow down the search space\n",
        "\n",
        "# Grid Search-> where all possible values of HPs are already known\n",
        "# if l1 could only switch b/w values [0.1,0.2,0.01, 0.001] -> exhaustive truth table of all HPs\n",
        "# LR = b/w [0.001, or 0.002]\n",
        "# Grid Search:\n",
        "# LR   l1          metric[accuracy-> max]\n",
        "# 0.001  0.1      86.66\n",
        "# 0.001  0.2      45\n",
        "# 0.001  0.01     ----exception-----\n",
        "# 0.001  0.001    -------div by zero-----\n",
        "# 0.002  0.1      23\n",
        "# 0.002  0.2      92\n",
        "# 0.002  0.01     92.4\n",
        "# 0.002  0.001    81\n",
        "# Grid search gives you BEST possible HP [iff your SEARCH space is finite!]\n",
        "# most time exhaustive algorithm for HP optimization!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDJDF0SABP1J"
      },
      "source": [
        "# Randomized Search\n",
        "# generate random pairs of HPs within the limit that YOU define\n",
        "# LR = (0.01, 0.02) -> many inf values possible\n",
        "# L1 = (0.01, 0.014) -> many inf values possible\n",
        "# 2 hours of time \n",
        "# ALL possible combinations will be tried\n",
        "# After time expiry, the best possible HP set will be returned to you!\n",
        "# best results??? NOPE!\n",
        "# fairly sufficient HP set to start with and optimize over a period of time\n",
        "#\n",
        "# Early Stopping\n",
        "# Early Stopping can help your model avoid wasting resources if model is not\n",
        "# performing well in initial stages\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT5Fw3FzC-JU",
        "outputId": "b655a860-64bd-48e8-90f1-bfbe3c9a39ea"
      },
      "source": [
        "modelx.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_10  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 64)                1088      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 169,537\n",
            "Trainable params: 169,537\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruimPI1cC_vJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}